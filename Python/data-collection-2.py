import requests
import pandas as pd
from time import sleep
import os

API_KEY = "bc9bda5ee7564df4aeaf4253f0d0e7ec"
BASE_URL = "https://api.rawg.io/api/games"
SAVE_DIR = "./datasets/rawg_by_year"
os.makedirs(SAVE_DIR, exist_ok=True)

for year in range(2000, 2025):
    save_path = f"{SAVE_DIR}/rawg_{year}.csv"

    # ì´ë¯¸ ìˆ˜ì§‘ëœ ì—°ë„ëŠ” ìŠ¤í‚µ
    if os.path.exists(save_path):
        print(f"{year}ë…„ ë°ì´í„° ì´ë¯¸ ì¡´ì¬")
        continue

    print(f"\nğŸ“† {year}ë…„ ë°ì´í„° ìˆ˜ì§‘")

    all_games = []
    page = 1

    while True:
        params = {
            "key": API_KEY,
            "dates": f"{year}-01-01,{year}-12-31",
            "page_size": 40,
            "page": page
        }

        try:
            r = requests.get(BASE_URL, params=params)
        except Exception as e:
            print(f"5ì´ˆ í›„ ì¬ì‹œë„")
            sleep(5)
            continue

        if r.status_code != 200:
            print(f"{year}, page {page}")
            sleep(3)
            break

        try:
            data = r.json()
        except ValueError:
            print(f"ë””ì½”ë”© {year}, page {page}")
            print(r.text[:200])
            sleep(3)
            break

        if "results" not in data or not data["results"]:
            print(f"{year}ë…„ {page}í˜ì´ì§€ ê²°ê³¼ ì—†ìŒ")
            break

        # ë°ì´í„° ì¶”ê°€
        all_games.extend(data["results"])
        print(f"{year}ë…„ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì™„ë£Œ ({len(data['results'])}ê°œ)")

        # ë‹¤ìŒ í˜ì´ì§€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        if not data.get("next"):
            break

        page += 1
        sleep(1.2)

    # ë°ì´í„° ì €ì¥
    if all_games:
        df = pd.json_normalize(all_games)
        df.to_csv(save_path, index=False, encoding="utf-8-sig")
        print(f"{year}ë…„ ë°ì´í„° ì €ì¥ ì™„ë£Œ ({len(df)}ê°œ)")
    else:
        print(f"{year}ë…„ì€ ë°ì´í„° ì—†ìŒ")

    sleep(2)
